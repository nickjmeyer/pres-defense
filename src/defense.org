#+title: Estimating optimal control strategies for large scale spatio-temporal decision problems
#+author: Nicholas J. Meyer

#+STARTUP: showeverything

#+REVEAL_ROOT: ../libs/reveal-js

#+REVEAL_THEME: simple

#+REVEAL_EXTRA_CSS: customize_theme.css

#+REVEAL_EXTRA_JS: ./custom.js

#+OPTIONS: toc:nil num:nil timestamp:nil reveal_single_file:t

#+REVEAL_TRANS: none

#+BIBLIOGRAPHY: ./sources.bib


* Thank you!

* Outline
  Need an outline...


* Model Based Epidemic Intervention Strategies
  :PROPERTIES:
  :HTML_CONTAINER_CLASS: centered-title
  :END:

** White Nose Syndrome
  #+REVEAL_HTML: <div class="columns">

  #+REVEAL_HTML: <div class="column">
  - Schoharie County, New York, 2006 cite:Blehert2009
  - Infectious fungus that is rapidly killing bats
  - Poses environmental, human health, and financial concerns
    cite:Boyles2011
  - Current treatments:
    - Heaters in caves
    - Artificial caves
    - Chemical treatments

  #+REVEAL_HTML: </div>

  #+REVEAL_HTML: <div class="column">
  [[./figures/wnsPhoto.jpg]]
  #+REVEAL_HTML: </div>

  #+REVEAL_HTML: </div>



* Semi-Parametric Epidemic Intervention Strategies
  :PROPERTIES:
  :HTML_CONTAINER_CLASS: centered-title
  :END:


* Pursuit Evasion
  :PROPERTIES:
  :HTML_CONTAINER_CLASS: centered-title
  :END:

** Motivating problems
  - National security
    - Domestic invasion
    - Search and destroy missions
  - Emergency response
    - Law enforcement responding to a fleeing suspect
  - Wildlife management
    - Tracking poachers of endangered animals

** Pursuit and Evasion
  - Formalize the search as evolving over a network of locations
  - All players move in discrete time
  - Possible objectives
    1. Evader tries to reach goal and pursuers try to stop the evader
    2. Pursuers try to catch evader and game continues until capture

** Pursuit and Evasion Demo
  [[./figures/animation.gif]]

** Game Setup
  - \(d\) pursuers
  - 1 evader
  - \(\lbrace 1, \ldots, L \rbrace\) nodes in the network
  - Order of events
    1. Pursuers gather and share state information
    2. Pursuers move to new locations
    3. Evader responds by moving to a new location
  - Game terminates when the evader has reached the goal or has been caught
    - The evader has been caught if adjacent to at least one pursuer
    - Finite time horizon

** Pursuers
  - *Goal*: Minimize expected time to capture
  - State information available to all pursuers at each time point
    - Locations of all pursuers
    - Indicator for whether or not evader has been caught
    - Information from informants and reliability of the source
      - Reliable, deceitful, noisy
    - Assume complete communication
  - New locations are restricted to a feasible set
    - E.g., can only move to adjacent locations
  - An action is a set of new locations for each agent

** Evader
  - *Goal*: Reach goal without being caught by pursuers
  - Only one evader
  - Movements restricted to feasible set (e.g., adjacent locations)

** Timeline
  [[./figures/timeline.png]]

** Player Strategies
  - Pursuers
    - Define \(H^t\) to be all current and past state information at
      time \(t\)
    - \(W^t\): Locations of all pursuers at time \(t\)
    - \(R^t\): Reward for the pursuers at time \(t\)
    - \(\pi = \lbrace \pi^0,\ldots,\pi^{T-1}\rbrace\): Strategy for
      all \(d\) pursuers
      - \(\pi^t\): Maps \(H^t\) to the set of feasible next locations
  - Evader:
    - \(\psi = \lbrace \psi^0, \ldots, \psi^{T-1}\rbrace\): Strategy
      for the evader
    - \(\psi^t\): Maps current location to the set of feasible next
      locations

** Optimal Pursuer Strategies
  - Value of the pursuer strategy \(\pi\) assuming evader follows
    \(\psi\) \[V(\pi; \psi) \triangleq \mathbb{E}^{\pi, \psi}\left(
    \sum_{t\ge 0} \gamma^t R^t\right) \] where \(\mathbb{E}^{\pi, \psi}\)
    denotes the expectation if pursuers follow \(\pi\) and the evader
    follows \(\psi\) and \(\gamma \in [0, 1)\) is the discount factor
  - Define \(J^t_\psi(\cdot | h^t)\) to be the posterior distribution
    of the evader's location given \(H^t = h^t\) and the evader is
    following \(\psi\)
  - For any \(\pi\) and \(\psi\), there exists a pursuer strategy
    \(\widetilde{\pi}\) depending on \(H^t\) through the current state
    and \(J^t_\psi(\cdot | H^t)\) such that \(V(\widetilde{\pi}, \psi)
    \ge V(\pi; \psi)\)

** Thompson Sampling
  [[./figures/thompson_sampling.png]]

** Estimating Optimal Pursuer Strategy

  - Q-function is a sufficient quantity for making optimal decisions
    \[Q^{*, \psi}(\boldsymbol{w}, \boldsymbol{J}, \boldsymbol{a}) = \mathbb{E}^{*,
    \psi}\left[\sum_{v\ge 0} \gamma^v R^{t + v} \bigg| \boldsymbol{W}^t =
    \boldsymbol{w}, \boldsymbol{J}^t = \boldsymbol{J},
    \boldsymbol{A}^t = \boldsymbol{a}\right]\]

  - Under the Markov assumption \[Q^{*, \psi}(\boldsymbol{w},
    \boldsymbol{J}, \boldsymbol{a}) = \mathbb{E}^{*, \psi}\left[R^t +
    \gamma \max_{\boldsymbol{a}'} Q^{*, \psi}(\boldsymbol{W}^{t+1},
    \boldsymbol{J}^{t+1}, \boldsymbol{a}') \bigg| \boldsymbol{W}^t =
    \boldsymbol{w}, \boldsymbol{J}^t = \boldsymbol{J},
    \boldsymbol{A}^t = \boldsymbol{a}\right]\]

  - Can write using a \(n\)-step roll out
    \[Q^{*, \psi}(\boldsymbol{w}, \boldsymbol{J}, \boldsymbol{a}) =
    \mathbb{E}^{*, \psi}\left[\sum_{v = 0}^{n-1} \gamma^v R^{t+v} +
    \gamma^n \max_{\boldsymbol{a}'} Q^{*,
    \psi}(\boldsymbol{W}^{t+n}, \boldsymbol{J}^{t+n}, \boldsymbol{a}')
    \bigg| \boldsymbol{W}^t = \boldsymbol{w}, \boldsymbol{J}^t =
    \boldsymbol{J}, \boldsymbol{A}^t = \boldsymbol{a}\right]\]

** Heuristic Strategy
  - Approximate Q-function using a heuristic strategy \[Q^{*,
    \psi}(\boldsymbol{w}, \boldsymbol{J}, \boldsymbol{a}) \approx
    \mathbb{E}^{*, \psi}\left[\sum_{v = 0}^{n-1} \gamma^v R^{t+v} +
    \gamma^{n} \max_{\boldsymbol{a}'} Q^{\pi_H,
    \psi}(\boldsymbol{W}^{t+n}, \boldsymbol{J}^{t+n}, \boldsymbol{a}')
    \bigg| \boldsymbol{W}^t = \boldsymbol{w}, \boldsymbol{J}^t =
    \boldsymbol{J}, \boldsymbol{A}^t = \boldsymbol{a}\right]\]

  - Heuristic strategy \(\pi_H\) is a variant of the /global-max/
    strategy
    - Find locations of the posterior with highest coverage
    - Select actions that move the pursuers closest to these locations

** Simulation Experiment Setup
  #+REVEAL_HTML: <div class="columns">

  #+REVEAL_HTML: <div class="column" style="padding: 1em 0">
  - Number of pursuers: 1, 2, 3
  - Number of steps before heuristic: 0, 1, 2
  - Evader is following a random walk indexed by goal and drift
  - Game ends when evader reaches the goal state or has been caught
  - 50 replications
  #+REVEAL_HTML: </div>

  #+REVEAL_HTML: <div class="column">
  [[./figures/sim_setup.png]]
  #+REVEAL_HTML: </div>

  #+REVEAL_HTML: </div>

** Simulation Experiment Results
  #+attr_html: :width 55%
  [[./figures/prob_capture.png]]

** Future Work
  - Estimate prior over evader behaviors using Nash process prior
  - Intelligent evader that adapts over time
  - Prioritization of capture zones
  - Incorporate additional actions besides movement


* Fun Tangents
  :PROPERTIES:
  :HTML_CONTAINER_CLASS: centered-title
  :END:


** Laser Foxes


** Snack Attack


* Acknowledgments
  A lot of people...

* References
  bibliography:./sources.bib
